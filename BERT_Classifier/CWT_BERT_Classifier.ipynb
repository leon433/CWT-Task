{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXoJ2V8n_vyb",
        "outputId": "d0736c46-0a60-4d30-dff6-ef066ff2b600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3DZGoYhiQqEi"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import re"
      ],
      "metadata": {
        "id": "UguZn1nCAk3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZJu5ZfLRy9M"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-dwpyXo6R2og"
      },
      "outputs": [],
      "source": [
        "# BERT\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnEml2COR51K",
        "outputId": "47f8f49d-07ca-4139-cf99-98ef484aea81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU.\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device=torch.device('cuda')\n",
        "  print('Using GPU.')\n",
        "else:\n",
        "  device=torch.device('cpu')\n",
        "  print('Using CPU.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "G9w2A_TE_fPe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz69qV0iUp_m",
        "outputId": "dc7ba7f3-2c4b-4c04-9989-6a9e73765443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DtypeWarning: Columns (0,1,3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ],
      "source": [
        "def load_data(filepath):\n",
        "  \"\"\"Load data and ensure filetypes. \"\"\"\n",
        "    df = pd.read_csv(filepath).dropna()\n",
        "    \n",
        "    dtype={'rating_review':float,\n",
        "           'review_full':'string'}\n",
        "    \n",
        "    df = df.astype(dtype)\n",
        "    \n",
        "    return df[['rating_review',\n",
        "               'review_full']]\n",
        "\n",
        "df = load_data('/content/drive/MyDrive/CWT Data/London_reviews.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is imbalanced (heavily skewed). Given size of dataset, use undersampling to balance out."
      ],
      "metadata": {
        "id": "jIJOjgoo_sdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rus = RandomUnderSampler(random_state=0, replacement=True)\n",
        "df_resampled, y_resampled = rus.fit_resample(df[['review_full', 'sample']], df.rating_review)\n",
        "# quick change to labels for BERT indexing\n",
        "y_resampled = y_resampled - 1\n",
        "y_resampled.value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "ojJbtf76AFsw",
        "outputId": "2d844c87-9828-461e-fde3-2e683cdc31a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fda87a55c50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing."
      ],
      "metadata": {
        "id": "9De-suIK_06E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_resampled.review_full.values\n",
        "y = y_resampled.values\n",
        "\n",
        "# Split dataset into train, validation, and test sets. \n",
        "X_train, X_rem, y_train, y_rem = train_test_split(X, y, test_size=0.70)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=0.15)"
      ],
      "metadata": {
        "id": "3RPILGE3AOeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7-hb8t-VSJ5V"
      },
      "outputs": [],
      "source": [
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N757JiTwSRBs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "bc0260560a9742d6979c5481ef0974b1",
            "7ea0be78bc0a4ce9a2300aff9904626c",
            "0c6ee89579184448b153ed5c3a04ff6c",
            "3a429b3258e44d738414e9615f062761",
            "288d2528c68346bb993da63b690ea394",
            "8db5374107834c2ead2bb4e0f29dfcfd",
            "20db29c280334d1c9a2f25d817e5e802",
            "4f303ffc51ee48a7a452728bafe3ffa2",
            "33b9323fb04644d7855eddf32faf134a",
            "b9829e0aa9184a0ea8709cc7aaa5bd31",
            "9bc0dc16fea84d8da6fe87a0469ef2a0",
            "1cd8a2bfe60f4a0786f322b107d51547",
            "630636c220a54fc3b001fce729c366bb",
            "63b2d0583a724e46962fc8a552791d2a",
            "ec07bef5055941e6a35d67f05fdae6d6",
            "6932b3917c904cd5b95ea63f7eb66405",
            "22573f36ebb049e78deb49abea79ba29",
            "7de209d55ad34e9884117a4124d1fea0",
            "74ddf32e38534128b5cbcd3bc8078c21",
            "7f75ad83c01c4ce58d8895985b3abb23",
            "3c0906e6b8d3451c9d0b03dbc2c45d8d",
            "dd3534601a074519bcd264340dab7d43",
            "9fce4a93c1ce4f3ba03d0d943d710f68",
            "91a632b3a9424573a558baaa68e16ea2",
            "5847586e0cc24ece9125b4cd7b2735bc",
            "39eac88e4a114f63bab6658d03e87727",
            "af79cb8b1edf42c68dada28f42318506",
            "590431fde48349b1abab0422aa8f9c72",
            "1c7b0c881c25489187be010f52fe7509",
            "00a52ed536e54368bde99bc5f4ab9b8d",
            "15548afeef224f16a9c92705c5e27237",
            "b284b522d77943e9a11de1d8b2ac6eb7",
            "a115d567faf340f98f2939eb604f66f9"
          ]
        },
        "outputId": "12518980-1522-4957-d20c-18742701159e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc0260560a9742d6979c5481ef0974b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cd8a2bfe60f4a0786f322b107d51547"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fce4a93c1ce4f3ba03d0d943d710f68"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xLcqUz3nSXrQ"
      },
      "outputs": [],
      "source": [
        "# Create a function to tokenize a set of texts for input to BERT model\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in tqdm(data):\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=512,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            truncation=True,\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(data, labels, batch_size):\n",
        "\n",
        "  # convert inputs\n",
        "  inputs, masks = preprocessing_for_bert(data)\n",
        "  labels = torch.tensor(labels)\n",
        "  labels = labels.type(torch.LongTensor)\n",
        "  \n",
        "  # arrange in batched dataloader\n",
        "  dataset = TensorDataset(inputs masks, labels)\n",
        "  sampler = RandomSampler(dataset)\n",
        "  dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
        "\n",
        "  return dataloader\n"
      ],
      "metadata": {
        "id": "vn0zFug9A_RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "train_dataloader = get_dataloader(X_train, y_train, batch_size=32)\n",
        "val_dataloader = get_dataloader(X_val, y_val, batch_size=32)"
      ],
      "metadata": {
        "id": "bk7g2f9rBXba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2UZ7Q-Ao5qpe"
      },
      "outputs": [],
      "source": [
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        \n",
        "        super(BertClassifier, self).__init__()\n",
        "        \n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 5\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVy5J8oy5ysE"
      },
      "outputs": [],
      "source": [
        "def initialize_model(epochs=4, train_dataloader):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tfPP2Dfm50jP"
      },
      "outputs": [],
      "source": [
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4Rn4AP3R55tb"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataloader, val_dataloader=None, epochs=4):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        \n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        total_loss_tracker = []\n",
        "        batch_loss_tracker = []\n",
        "        batch_counts_tracker = []\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                batch_loss_tracker.append(batch_loss)\n",
        "                batch_counts_tracker.append(batch_counts)\n",
        "                total_loss_tracker.append(total_loss)\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        \n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        PATH = 'bert_eng_full_review_' + str(epoch_i) + '.pt'\n",
        "        torch.save({\n",
        "            'epoch': epoch_i + 1,\n",
        "            'model_state_dict': bert_classifier.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict(),\n",
        "            'batch_loss_tracker': batch_loss_tracker,\n",
        "            'total_loss_tracker': total_loss_tracker,\n",
        "            'batch_counts_tracker': batch_counts_tracker\n",
        "            }, PATH)\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8e47da83e3904d6384710e7563d6ff60",
            "72f6f4f313a2436c8fe887fcfd86095e",
            "e6b74e1e2173451f93658099fae7e87b",
            "f9f6900239d14043b17699119a019542",
            "24a25b9cca0a43aa801cbee96dab6eba",
            "a50cd813e3854aa68ee429fde7afb2b3",
            "04186e99b4594f57a4bff86682915c68",
            "7fa170d651cc4e5b816f238402bd9b2e",
            "c81261a2391d47e39e1d1a00d2a345c4",
            "2b350421366d4fc59bcb91429aa342ca",
            "293fee50998f47c498ea51200f880f55"
          ]
        },
        "id": "jL-0xwkl5-dm",
        "outputId": "bf140c47-5639-4b3c-fbcc-ef89342f9311"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e47da83e3904d6384710e7563d6ff60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   1.441595   |     -      |     -     |   18.01  \n",
            "   1    |   40    |   1.115404   |     -      |     -     |   14.11  \n",
            "   1    |   60    |   0.955047   |     -      |     -     |   14.09  \n",
            "   1    |   80    |   0.952662   |     -      |     -     |   14.09  \n",
            "   1    |   100   |   0.913323   |     -      |     -     |   14.10  \n",
            "   1    |   120   |   0.901958   |     -      |     -     |   14.09  \n",
            "   1    |   140   |   0.875026   |     -      |     -     |   14.12  \n",
            "   1    |   160   |   0.878141   |     -      |     -     |   14.08  \n",
            "   1    |   180   |   0.902293   |     -      |     -     |   14.09  \n",
            "   1    |   200   |   0.816749   |     -      |     -     |   14.07  \n",
            "   1    |   220   |   0.849118   |     -      |     -     |   14.09  \n",
            "   1    |   240   |   0.870787   |     -      |     -     |   14.10  \n",
            "   1    |   260   |   0.825568   |     -      |     -     |   14.08  \n",
            "   1    |   280   |   0.783410   |     -      |     -     |   14.10  \n",
            "   1    |   300   |   0.794499   |     -      |     -     |   14.08  \n",
            "   1    |   320   |   0.810774   |     -      |     -     |   14.08  \n",
            "   1    |   340   |   0.829610   |     -      |     -     |   14.07  \n",
            "   1    |   360   |   0.805198   |     -      |     -     |   14.09  \n",
            "   1    |   380   |   0.829475   |     -      |     -     |   14.07  \n",
            "   1    |   400   |   0.803119   |     -      |     -     |   14.10  \n",
            "   1    |   420   |   0.823119   |     -      |     -     |   14.09  \n",
            "   1    |   440   |   0.789729   |     -      |     -     |   14.08  \n",
            "   1    |   460   |   0.797783   |     -      |     -     |   14.09  \n",
            "   1    |   480   |   0.875087   |     -      |     -     |   14.08  \n",
            "   1    |   500   |   0.817296   |     -      |     -     |   14.07  \n",
            "   1    |   520   |   0.758629   |     -      |     -     |   14.09  \n",
            "   1    |   540   |   0.778667   |     -      |     -     |   14.09  \n",
            "   1    |   560   |   0.740690   |     -      |     -     |   14.07  \n",
            "   1    |   580   |   0.813429   |     -      |     -     |   14.08  \n",
            "   1    |   600   |   0.797702   |     -      |     -     |   14.09  \n",
            "   1    |   620   |   0.805141   |     -      |     -     |   14.08  \n",
            "   1    |   640   |   0.758858   |     -      |     -     |   14.08  \n",
            "   1    |   660   |   0.801568   |     -      |     -     |   14.09  \n",
            "   1    |   680   |   0.786734   |     -      |     -     |   14.09  \n",
            "   1    |   700   |   0.752597   |     -      |     -     |   14.09  \n",
            "   1    |   720   |   0.765857   |     -      |     -     |   14.09  \n",
            "   1    |   740   |   0.743526   |     -      |     -     |   14.09  \n",
            "   1    |   760   |   0.782136   |     -      |     -     |   14.08  \n",
            "   1    |   780   |   0.797182   |     -      |     -     |   14.08  \n",
            "   1    |   800   |   0.741338   |     -      |     -     |   14.08  \n",
            "   1    |   820   |   0.707234   |     -      |     -     |   14.08  \n",
            "   1    |   840   |   0.756578   |     -      |     -     |   14.10  \n",
            "   1    |   860   |   0.701848   |     -      |     -     |   14.07  \n",
            "   1    |   880   |   0.712171   |     -      |     -     |   14.09  \n",
            "   1    |   900   |   0.713289   |     -      |     -     |   14.09  \n",
            "   1    |   920   |   0.755462   |     -      |     -     |   14.08  \n",
            "   1    |   940   |   0.786033   |     -      |     -     |   14.08  \n",
            "   1    |   960   |   0.770915   |     -      |     -     |   14.08  \n",
            "   1    |   980   |   0.793470   |     -      |     -     |   14.08  \n",
            "   1    |  1000   |   0.761669   |     -      |     -     |   14.08  \n",
            "   1    |  1020   |   0.745422   |     -      |     -     |   14.09  \n",
            "   1    |  1040   |   0.817533   |     -      |     -     |   14.10  \n",
            "   1    |  1060   |   0.784791   |     -      |     -     |   14.10  \n",
            "   1    |  1080   |   0.710154   |     -      |     -     |   14.08  \n",
            "   1    |  1100   |   0.787286   |     -      |     -     |   14.10  \n",
            "   1    |  1120   |   0.721770   |     -      |     -     |   14.10  \n",
            "   1    |  1140   |   0.797303   |     -      |     -     |   14.08  \n",
            "   1    |  1160   |   0.781326   |     -      |     -     |   14.09  \n",
            "   1    |  1180   |   0.770939   |     -      |     -     |   14.10  \n",
            "   1    |  1200   |   0.720315   |     -      |     -     |   14.07  \n",
            "   1    |  1220   |   0.693440   |     -      |     -     |   14.07  \n",
            "   1    |  1240   |   0.789960   |     -      |     -     |   14.09  \n",
            "   1    |  1260   |   0.731651   |     -      |     -     |   14.07  \n",
            "   1    |  1280   |   0.740509   |     -      |     -     |   14.06  \n",
            "   1    |  1300   |   0.759403   |     -      |     -     |   14.09  \n",
            "   1    |  1320   |   0.688582   |     -      |     -     |   14.07  \n",
            "   1    |  1340   |   0.802753   |     -      |     -     |   14.08  \n",
            "   1    |  1360   |   0.747962   |     -      |     -     |   14.10  \n",
            "   1    |  1380   |   0.768805   |     -      |     -     |   14.07  \n",
            "   1    |  1400   |   0.730222   |     -      |     -     |   14.08  \n",
            "   1    |  1420   |   0.711139   |     -      |     -     |   14.09  \n",
            "   1    |  1440   |   0.712536   |     -      |     -     |   14.08  \n",
            "   1    |  1460   |   0.794492   |     -      |     -     |   14.09  \n",
            "   1    |  1480   |   0.741230   |     -      |     -     |   14.08  \n",
            "   1    |  1500   |   0.707852   |     -      |     -     |   14.07  \n",
            "   1    |  1520   |   0.707685   |     -      |     -     |   14.08  \n",
            "   1    |  1540   |   0.798538   |     -      |     -     |   14.08  \n",
            "   1    |  1560   |   0.721675   |     -      |     -     |   14.07  \n",
            "   1    |  1580   |   0.702099   |     -      |     -     |   14.08  \n",
            "   1    |  1600   |   0.733184   |     -      |     -     |   14.08  \n",
            "   1    |  1620   |   0.746141   |     -      |     -     |   14.08  \n",
            "   1    |  1640   |   0.782846   |     -      |     -     |   14.09  \n",
            "   1    |  1660   |   0.778531   |     -      |     -     |   14.10  \n",
            "   1    |  1680   |   0.693099   |     -      |     -     |   14.07  \n",
            "   1    |  1700   |   0.716481   |     -      |     -     |   14.08  \n",
            "   1    |  1720   |   0.719097   |     -      |     -     |   14.10  \n",
            "   1    |  1740   |   0.784264   |     -      |     -     |   14.10  \n",
            "   1    |  1760   |   0.764002   |     -      |     -     |   14.08  \n",
            "   1    |  1780   |   0.729003   |     -      |     -     |   14.07  \n",
            "   1    |  1800   |   0.725130   |     -      |     -     |   14.08  \n",
            "   1    |  1820   |   0.706678   |     -      |     -     |   14.10  \n",
            "   1    |  1840   |   0.685669   |     -      |     -     |   14.09  \n",
            "   1    |  1860   |   0.725435   |     -      |     -     |   14.08  \n",
            "   1    |  1880   |   0.704210   |     -      |     -     |   14.07  \n",
            "   1    |  1900   |   0.718257   |     -      |     -     |   14.09  \n",
            "   1    |  1920   |   0.731991   |     -      |     -     |   14.10  \n",
            "   1    |  1940   |   0.782332   |     -      |     -     |   14.09  \n",
            "   1    |  1960   |   0.685710   |     -      |     -     |   14.10  \n",
            "   1    |  1980   |   0.710404   |     -      |     -     |   14.09  \n",
            "   1    |  2000   |   0.705786   |     -      |     -     |   14.09  \n",
            "   1    |  2020   |   0.722691   |     -      |     -     |   14.08  \n",
            "   1    |  2040   |   0.705822   |     -      |     -     |   14.08  \n",
            "   1    |  2060   |   0.697888   |     -      |     -     |   14.10  \n",
            "   1    |  2080   |   0.689698   |     -      |     -     |   14.09  \n",
            "   1    |  2100   |   0.743044   |     -      |     -     |   14.09  \n",
            "   1    |  2120   |   0.687661   |     -      |     -     |   14.08  \n",
            "   1    |  2140   |   0.697884   |     -      |     -     |   14.08  \n",
            "   1    |  2160   |   0.768126   |     -      |     -     |   14.09  \n",
            "   1    |  2180   |   0.732644   |     -      |     -     |   14.13  \n",
            "   1    |  2200   |   0.720063   |     -      |     -     |   14.08  \n",
            "   1    |  2220   |   0.702333   |     -      |     -     |   14.08  \n",
            "   1    |  2240   |   0.761400   |     -      |     -     |   14.11  \n",
            "   1    |  2260   |   0.708604   |     -      |     -     |   14.10  \n",
            "   1    |  2280   |   0.727054   |     -      |     -     |   14.11  \n",
            "   1    |  2300   |   0.704017   |     -      |     -     |   14.09  \n",
            "   1    |  2320   |   0.724789   |     -      |     -     |   14.11  \n",
            "   1    |  2340   |   0.759186   |     -      |     -     |   14.09  \n",
            "   1    |  2360   |   0.703347   |     -      |     -     |   14.09  \n",
            "   1    |  2380   |   0.643138   |     -      |     -     |   14.10  \n",
            "   1    |  2400   |   0.678003   |     -      |     -     |   14.11  \n",
            "   1    |  2420   |   0.745762   |     -      |     -     |   14.08  \n",
            "   1    |  2440   |   0.696853   |     -      |     -     |   14.07  \n",
            "   1    |  2460   |   0.697765   |     -      |     -     |   14.08  \n",
            "   1    |  2480   |   0.675219   |     -      |     -     |   14.10  \n",
            "   1    |  2500   |   0.707516   |     -      |     -     |   14.11  \n",
            "   1    |  2520   |   0.694326   |     -      |     -     |   14.08  \n",
            "   1    |  2540   |   0.631035   |     -      |     -     |   14.09  \n",
            "   1    |  2560   |   0.693095   |     -      |     -     |   14.09  \n",
            "   1    |  2580   |   0.716998   |     -      |     -     |   14.08  \n",
            "   1    |  2600   |   0.747977   |     -      |     -     |   14.10  \n",
            "   1    |  2620   |   0.678994   |     -      |     -     |   14.10  \n",
            "   1    |  2640   |   0.768940   |     -      |     -     |   14.08  \n",
            "   1    |  2660   |   0.678553   |     -      |     -     |   14.10  \n",
            "   1    |  2680   |   0.747407   |     -      |     -     |   14.08  \n",
            "   1    |  2700   |   0.693869   |     -      |     -     |   14.09  \n",
            "   1    |  2720   |   0.745548   |     -      |     -     |   14.09  \n",
            "   1    |  2740   |   0.732361   |     -      |     -     |   14.09  \n",
            "   1    |  2760   |   0.670818   |     -      |     -     |   14.11  \n",
            "   1    |  2780   |   0.682932   |     -      |     -     |   14.08  \n",
            "   1    |  2800   |   0.731645   |     -      |     -     |   14.10  \n",
            "   1    |  2820   |   0.727078   |     -      |     -     |   14.09  \n",
            "   1    |  2840   |   0.708922   |     -      |     -     |   14.09  \n",
            "   1    |  2860   |   0.689638   |     -      |     -     |   14.09  \n",
            "   1    |  2880   |   0.759701   |     -      |     -     |   14.08  \n",
            "   1    |  2900   |   0.700390   |     -      |     -     |   14.08  \n",
            "   1    |  2920   |   0.691031   |     -      |     -     |   14.09  \n",
            "   1    |  2940   |   0.643747   |     -      |     -     |   14.10  \n",
            "   1    |  2960   |   0.702685   |     -      |     -     |   14.08  \n",
            "   1    |  2980   |   0.664680   |     -      |     -     |   14.08  \n",
            "   1    |  3000   |   0.680811   |     -      |     -     |   14.09  \n",
            "   1    |  3020   |   0.719106   |     -      |     -     |   14.09  \n",
            "   1    |  3040   |   0.728354   |     -      |     -     |   14.08  \n",
            "   1    |  3060   |   0.682273   |     -      |     -     |   14.08  \n",
            "   1    |  3080   |   0.709253   |     -      |     -     |   14.08  \n",
            "   1    |  3100   |   0.683922   |     -      |     -     |   14.09  \n",
            "   1    |  3120   |   0.752430   |     -      |     -     |   14.09  \n",
            "   1    |  3140   |   0.717165   |     -      |     -     |   14.08  \n",
            "   1    |  3160   |   0.729750   |     -      |     -     |   14.08  \n",
            "   1    |  3180   |   0.709517   |     -      |     -     |   14.07  \n",
            "   1    |  3200   |   0.718477   |     -      |     -     |   14.07  \n",
            "   1    |  3220   |   0.690677   |     -      |     -     |   14.09  \n",
            "   1    |  3240   |   0.719118   |     -      |     -     |   14.09  \n",
            "   1    |  3260   |   0.702267   |     -      |     -     |   14.08  \n",
            "   1    |  3280   |   0.710948   |     -      |     -     |   14.08  \n",
            "   1    |  3300   |   0.701660   |     -      |     -     |   14.08  \n",
            "   1    |  3320   |   0.709005   |     -      |     -     |   14.10  \n",
            "   1    |  3340   |   0.773822   |     -      |     -     |   14.10  \n",
            "   1    |  3360   |   0.709790   |     -      |     -     |   14.09  \n",
            "   1    |  3380   |   0.706785   |     -      |     -     |   14.10  \n",
            "   1    |  3400   |   0.754831   |     -      |     -     |   14.07  \n",
            "   1    |  3420   |   0.717044   |     -      |     -     |   14.07  \n",
            "   1    |  3440   |   0.674701   |     -      |     -     |   14.09  \n",
            "   1    |  3460   |   0.684423   |     -      |     -     |   14.10  \n",
            "   1    |  3480   |   0.718360   |     -      |     -     |   14.09  \n",
            "   1    |  3500   |   0.707409   |     -      |     -     |   14.09  \n",
            "   1    |  3520   |   0.721088   |     -      |     -     |   14.09  \n",
            "   1    |  3540   |   0.667723   |     -      |     -     |   14.07  \n",
            "   1    |  3560   |   0.700899   |     -      |     -     |   14.09  \n",
            "   1    |  3580   |   0.684846   |     -      |     -     |   14.08  \n",
            "   1    |  3600   |   0.698882   |     -      |     -     |   14.08  \n",
            "   1    |  3620   |   0.674288   |     -      |     -     |   14.08  \n",
            "   1    |  3640   |   0.692682   |     -      |     -     |   14.08  \n",
            "   1    |  3660   |   0.675821   |     -      |     -     |   14.08  \n",
            "   1    |  3680   |   0.648994   |     -      |     -     |   14.08  \n",
            "   1    |  3700   |   0.656186   |     -      |     -     |   14.10  \n",
            "   1    |  3720   |   0.710929   |     -      |     -     |   14.09  \n",
            "   1    |  3740   |   0.719345   |     -      |     -     |   14.07  \n",
            "   1    |  3760   |   0.701190   |     -      |     -     |   14.07  \n",
            "   1    |  3780   |   0.645817   |     -      |     -     |   14.08  \n",
            "   1    |  3800   |   0.701866   |     -      |     -     |   14.07  \n",
            "   1    |  3820   |   0.648584   |     -      |     -     |   14.07  \n",
            "   1    |  3840   |   0.654161   |     -      |     -     |   14.11  \n",
            "   1    |  3860   |   0.664954   |     -      |     -     |   14.10  \n",
            "   1    |  3880   |   0.723011   |     -      |     -     |   14.08  \n",
            "   1    |  3900   |   0.690148   |     -      |     -     |   14.09  \n",
            "   1    |  3920   |   0.671889   |     -      |     -     |   14.09  \n",
            "   1    |  3940   |   0.737501   |     -      |     -     |   14.08  \n",
            "   1    |  3960   |   0.727483   |     -      |     -     |   14.10  \n",
            "   1    |  3980   |   0.713860   |     -      |     -     |   14.08  \n",
            "   1    |  4000   |   0.710262   |     -      |     -     |   14.08  \n",
            "   1    |  4020   |   0.696917   |     -      |     -     |   14.08  \n",
            "   1    |  4040   |   0.664687   |     -      |     -     |   14.08  \n",
            "   1    |  4060   |   0.693279   |     -      |     -     |   14.08  \n",
            "   1    |  4080   |   0.729986   |     -      |     -     |   14.08  \n",
            "   1    |  4100   |   0.680913   |     -      |     -     |   14.07  \n",
            "   1    |  4120   |   0.682734   |     -      |     -     |   14.07  \n",
            "   1    |  4140   |   0.689366   |     -      |     -     |   14.11  \n",
            "   1    |  4160   |   0.673699   |     -      |     -     |   14.07  \n",
            "   1    |  4180   |   0.658416   |     -      |     -     |   14.08  \n",
            "   1    |  4200   |   0.695832   |     -      |     -     |   14.08  \n",
            "   1    |  4220   |   0.687860   |     -      |     -     |   14.10  \n",
            "   1    |  4240   |   0.626430   |     -      |     -     |   14.08  \n",
            "   1    |  4260   |   0.679862   |     -      |     -     |   14.09  \n",
            "   1    |  4280   |   0.653409   |     -      |     -     |   14.07  \n",
            "   1    |  4300   |   0.612245   |     -      |     -     |   14.10  \n",
            "   1    |  4320   |   0.715758   |     -      |     -     |   14.09  \n",
            "   1    |  4340   |   0.676341   |     -      |     -     |   14.07  \n",
            "   1    |  4360   |   0.647258   |     -      |     -     |   14.09  \n",
            "   1    |  4380   |   0.648659   |     -      |     -     |   14.07  \n",
            "   1    |  4400   |   0.717894   |     -      |     -     |   14.08  \n",
            "   1    |  4420   |   0.707275   |     -      |     -     |   14.07  \n",
            "   1    |  4440   |   0.678670   |     -      |     -     |   14.11  \n",
            "   1    |  4460   |   0.651559   |     -      |     -     |   14.09  \n",
            "   1    |  4480   |   0.725697   |     -      |     -     |   14.07  \n",
            "   1    |  4500   |   0.735802   |     -      |     -     |   14.07  \n",
            "   1    |  4520   |   0.673475   |     -      |     -     |   14.08  \n",
            "   1    |  4540   |   0.692786   |     -      |     -     |   14.08  \n",
            "   1    |  4560   |   0.698018   |     -      |     -     |   14.10  \n",
            "   1    |  4580   |   0.731562   |     -      |     -     |   14.07  \n",
            "   1    |  4600   |   0.650633   |     -      |     -     |   14.07  \n",
            "   1    |  4620   |   0.692456   |     -      |     -     |   14.10  \n",
            "   1    |  4640   |   0.665745   |     -      |     -     |   14.07  \n",
            "   1    |  4660   |   0.645934   |     -      |     -     |   14.08  \n",
            "   1    |  4680   |   0.678139   |     -      |     -     |   14.07  \n",
            "   1    |  4700   |   0.698600   |     -      |     -     |   14.07  \n",
            "   1    |  4720   |   0.669096   |     -      |     -     |   14.08  \n",
            "   1    |  4740   |   0.641258   |     -      |     -     |   14.07  \n",
            "   1    |  4760   |   0.691407   |     -      |     -     |   14.08  \n",
            "   1    |  4780   |   0.664644   |     -      |     -     |   14.08  \n",
            "   1    |  4800   |   0.701252   |     -      |     -     |   14.09  \n",
            "   1    |  4820   |   0.670806   |     -      |     -     |   14.08  \n",
            "   1    |  4840   |   0.678271   |     -      |     -     |   14.08  \n",
            "   1    |  4860   |   0.653365   |     -      |     -     |   14.08  \n",
            "   1    |  4880   |   0.693550   |     -      |     -     |   14.09  \n",
            "   1    |  4900   |   0.715892   |     -      |     -     |   14.09  \n",
            "   1    |  4920   |   0.639021   |     -      |     -     |   14.13  \n",
            "   1    |  4940   |   0.704715   |     -      |     -     |   14.14  \n",
            "   1    |  4960   |   0.671840   |     -      |     -     |   14.08  \n",
            "   1    |  4980   |   0.722338   |     -      |     -     |   14.11  \n",
            "   1    |  5000   |   0.660635   |     -      |     -     |   14.08  \n",
            "   1    |  5020   |   0.692199   |     -      |     -     |   14.10  \n",
            "   1    |  5040   |   0.708405   |     -      |     -     |   14.07  \n",
            "   1    |  5052   |   0.665787   |     -      |     -     |   8.33   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.730340   |  0.670274  |   70.67   |  3687.97 \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.624869   |     -      |     -     |   14.82  \n",
            "   2    |   40    |   0.615673   |     -      |     -     |   14.08  \n",
            "   2    |   60    |   0.564243   |     -      |     -     |   14.08  \n",
            "   2    |   80    |   0.600762   |     -      |     -     |   14.10  \n",
            "   2    |   100   |   0.654761   |     -      |     -     |   14.10  \n",
            "   2    |   120   |   0.595535   |     -      |     -     |   14.09  \n",
            "   2    |   140   |   0.617057   |     -      |     -     |   14.08  \n",
            "   2    |   160   |   0.562314   |     -      |     -     |   14.09  \n",
            "   2    |   180   |   0.621395   |     -      |     -     |   14.10  \n",
            "   2    |   200   |   0.609884   |     -      |     -     |   14.07  \n",
            "   2    |   220   |   0.586730   |     -      |     -     |   14.08  \n",
            "   2    |   240   |   0.592907   |     -      |     -     |   14.07  \n",
            "   2    |   260   |   0.580872   |     -      |     -     |   14.08  \n",
            "   2    |   280   |   0.568538   |     -      |     -     |   14.10  \n",
            "   2    |   300   |   0.609806   |     -      |     -     |   14.10  \n",
            "   2    |   320   |   0.595582   |     -      |     -     |   14.07  \n",
            "   2    |   340   |   0.575372   |     -      |     -     |   14.08  \n",
            "   2    |   360   |   0.546005   |     -      |     -     |   14.09  \n",
            "   2    |   380   |   0.581055   |     -      |     -     |   14.09  \n",
            "   2    |   400   |   0.605160   |     -      |     -     |   14.11  \n",
            "   2    |   420   |   0.590002   |     -      |     -     |   14.07  \n",
            "   2    |   440   |   0.557440   |     -      |     -     |   14.08  \n",
            "   2    |   460   |   0.639798   |     -      |     -     |   14.08  \n",
            "   2    |   480   |   0.565731   |     -      |     -     |   14.07  \n",
            "   2    |   500   |   0.594585   |     -      |     -     |   14.08  \n",
            "   2    |   520   |   0.592452   |     -      |     -     |   14.07  \n",
            "   2    |   540   |   0.619557   |     -      |     -     |   14.08  \n",
            "   2    |   560   |   0.602327   |     -      |     -     |   14.07  \n",
            "   2    |   580   |   0.517993   |     -      |     -     |   14.08  \n",
            "   2    |   600   |   0.575753   |     -      |     -     |   14.08  \n",
            "   2    |   620   |   0.588442   |     -      |     -     |   14.08  \n",
            "   2    |   640   |   0.593523   |     -      |     -     |   14.08  \n",
            "   2    |   660   |   0.622262   |     -      |     -     |   14.11  \n",
            "   2    |   680   |   0.621688   |     -      |     -     |   14.10  \n",
            "   2    |   700   |   0.580013   |     -      |     -     |   14.08  \n",
            "   2    |   720   |   0.564750   |     -      |     -     |   14.08  \n",
            "   2    |   740   |   0.622256   |     -      |     -     |   14.08  \n",
            "   2    |   760   |   0.574617   |     -      |     -     |   14.07  \n",
            "   2    |   780   |   0.566993   |     -      |     -     |   14.07  \n",
            "   2    |   800   |   0.569337   |     -      |     -     |   14.10  \n",
            "   2    |   820   |   0.673463   |     -      |     -     |   14.08  \n",
            "   2    |   840   |   0.596969   |     -      |     -     |   14.10  \n",
            "   2    |   860   |   0.528862   |     -      |     -     |   14.08  \n",
            "   2    |   880   |   0.565002   |     -      |     -     |   14.10  \n",
            "   2    |   900   |   0.551583   |     -      |     -     |   14.07  \n",
            "   2    |   920   |   0.600911   |     -      |     -     |   14.09  \n",
            "   2    |   940   |   0.598560   |     -      |     -     |   14.10  \n",
            "   2    |   960   |   0.559981   |     -      |     -     |   14.08  \n",
            "   2    |   980   |   0.556287   |     -      |     -     |   14.09  \n",
            "   2    |  1000   |   0.569346   |     -      |     -     |   14.08  \n",
            "   2    |  1020   |   0.651939   |     -      |     -     |   14.08  \n",
            "   2    |  1040   |   0.575320   |     -      |     -     |   14.08  \n",
            "   2    |  1060   |   0.571000   |     -      |     -     |   14.10  \n",
            "   2    |  1080   |   0.549474   |     -      |     -     |   14.08  \n",
            "   2    |  1100   |   0.628450   |     -      |     -     |   14.08  \n",
            "   2    |  1120   |   0.585470   |     -      |     -     |   14.07  \n",
            "   2    |  1140   |   0.594096   |     -      |     -     |   14.09  \n",
            "   2    |  1160   |   0.583908   |     -      |     -     |   14.08  \n",
            "   2    |  1180   |   0.573754   |     -      |     -     |   14.08  \n",
            "   2    |  1200   |   0.559518   |     -      |     -     |   14.09  \n",
            "   2    |  1220   |   0.615038   |     -      |     -     |   14.08  \n",
            "   2    |  1240   |   0.570114   |     -      |     -     |   14.11  \n",
            "   2    |  1260   |   0.596770   |     -      |     -     |   14.08  \n",
            "   2    |  1280   |   0.575231   |     -      |     -     |   14.08  \n",
            "   2    |  1300   |   0.558156   |     -      |     -     |   14.08  \n",
            "   2    |  1320   |   0.637319   |     -      |     -     |   14.08  \n",
            "   2    |  1340   |   0.615202   |     -      |     -     |   14.08  \n",
            "   2    |  1360   |   0.617602   |     -      |     -     |   14.08  \n",
            "   2    |  1380   |   0.566255   |     -      |     -     |   14.09  \n",
            "   2    |  1400   |   0.571642   |     -      |     -     |   14.10  \n",
            "   2    |  1420   |   0.556598   |     -      |     -     |   14.09  \n",
            "   2    |  1440   |   0.590710   |     -      |     -     |   14.08  \n",
            "   2    |  1460   |   0.549931   |     -      |     -     |   14.09  \n",
            "   2    |  1480   |   0.521752   |     -      |     -     |   14.08  \n",
            "   2    |  1500   |   0.587799   |     -      |     -     |   14.09  \n",
            "   2    |  1520   |   0.586943   |     -      |     -     |   14.10  \n",
            "   2    |  1540   |   0.605179   |     -      |     -     |   14.09  \n",
            "   2    |  1560   |   0.584636   |     -      |     -     |   14.09  \n",
            "   2    |  1580   |   0.549828   |     -      |     -     |   14.07  \n",
            "   2    |  1600   |   0.653156   |     -      |     -     |   14.08  \n",
            "   2    |  1620   |   0.611704   |     -      |     -     |   14.07  \n",
            "   2    |  1640   |   0.587867   |     -      |     -     |   14.07  \n",
            "   2    |  1660   |   0.566858   |     -      |     -     |   14.07  \n",
            "   2    |  1680   |   0.579320   |     -      |     -     |   14.08  \n",
            "   2    |  1700   |   0.593220   |     -      |     -     |   14.09  \n",
            "   2    |  1720   |   0.575492   |     -      |     -     |   14.08  \n",
            "   2    |  1740   |   0.588063   |     -      |     -     |   14.09  \n",
            "   2    |  1760   |   0.598001   |     -      |     -     |   14.08  \n",
            "   2    |  1780   |   0.576039   |     -      |     -     |   14.09  \n",
            "   2    |  1800   |   0.588985   |     -      |     -     |   14.07  \n",
            "   2    |  1820   |   0.619842   |     -      |     -     |   14.09  \n",
            "   2    |  1840   |   0.593739   |     -      |     -     |   14.08  \n",
            "   2    |  1860   |   0.579197   |     -      |     -     |   14.08  \n",
            "   2    |  1880   |   0.626092   |     -      |     -     |   14.09  \n",
            "   2    |  1900   |   0.564955   |     -      |     -     |   14.08  \n",
            "   2    |  1920   |   0.587816   |     -      |     -     |   14.08  \n",
            "   2    |  1940   |   0.633464   |     -      |     -     |   14.07  \n",
            "   2    |  1960   |   0.566086   |     -      |     -     |   14.08  \n",
            "   2    |  1980   |   0.611855   |     -      |     -     |   14.07  \n",
            "   2    |  2000   |   0.547678   |     -      |     -     |   14.07  \n",
            "   2    |  2020   |   0.551031   |     -      |     -     |   14.08  \n",
            "   2    |  2040   |   0.613359   |     -      |     -     |   14.09  \n",
            "   2    |  2060   |   0.597818   |     -      |     -     |   14.09  \n",
            "   2    |  2080   |   0.579591   |     -      |     -     |   14.08  \n",
            "   2    |  2100   |   0.565531   |     -      |     -     |   14.08  \n",
            "   2    |  2120   |   0.531792   |     -      |     -     |   14.08  \n",
            "   2    |  2140   |   0.544175   |     -      |     -     |   14.09  \n",
            "   2    |  2160   |   0.617495   |     -      |     -     |   14.08  \n",
            "   2    |  2180   |   0.614418   |     -      |     -     |   14.11  \n",
            "   2    |  2200   |   0.606033   |     -      |     -     |   14.09  \n",
            "   2    |  2220   |   0.528736   |     -      |     -     |   14.09  \n",
            "   2    |  2240   |   0.632357   |     -      |     -     |   14.10  \n",
            "   2    |  2260   |   0.608115   |     -      |     -     |   14.10  \n",
            "   2    |  2280   |   0.561734   |     -      |     -     |   14.09  \n",
            "   2    |  2300   |   0.559197   |     -      |     -     |   14.08  \n",
            "   2    |  2320   |   0.541233   |     -      |     -     |   14.08  \n",
            "   2    |  2340   |   0.560058   |     -      |     -     |   14.10  \n",
            "   2    |  2360   |   0.546953   |     -      |     -     |   14.07  \n",
            "   2    |  2380   |   0.589787   |     -      |     -     |   14.10  \n",
            "   2    |  2400   |   0.548335   |     -      |     -     |   14.08  \n",
            "   2    |  2420   |   0.532130   |     -      |     -     |   14.07  \n",
            "   2    |  2440   |   0.544470   |     -      |     -     |   14.08  \n",
            "   2    |  2460   |   0.624622   |     -      |     -     |   14.08  \n",
            "   2    |  2480   |   0.517090   |     -      |     -     |   14.08  \n",
            "   2    |  2500   |   0.512698   |     -      |     -     |   14.07  \n",
            "   2    |  2520   |   0.595711   |     -      |     -     |   14.08  \n",
            "   2    |  2540   |   0.588595   |     -      |     -     |   14.08  \n",
            "   2    |  2560   |   0.559530   |     -      |     -     |   14.12  \n",
            "   2    |  2580   |   0.553543   |     -      |     -     |   14.11  \n",
            "   2    |  2600   |   0.563329   |     -      |     -     |   14.09  \n",
            "   2    |  2620   |   0.529136   |     -      |     -     |   14.08  \n",
            "   2    |  2640   |   0.572685   |     -      |     -     |   14.08  \n",
            "   2    |  2660   |   0.544460   |     -      |     -     |   14.09  \n",
            "   2    |  2680   |   0.548064   |     -      |     -     |   14.10  \n",
            "   2    |  2700   |   0.625352   |     -      |     -     |   14.08  \n",
            "   2    |  2720   |   0.601923   |     -      |     -     |   14.09  \n",
            "   2    |  2740   |   0.522183   |     -      |     -     |   14.12  \n",
            "   2    |  2760   |   0.605027   |     -      |     -     |   14.08  \n",
            "   2    |  2780   |   0.556128   |     -      |     -     |   14.09  \n",
            "   2    |  2800   |   0.565612   |     -      |     -     |   14.08  \n",
            "   2    |  2820   |   0.577909   |     -      |     -     |   14.08  \n",
            "   2    |  2840   |   0.511866   |     -      |     -     |   14.10  \n",
            "   2    |  2860   |   0.562883   |     -      |     -     |   14.08  \n",
            "   2    |  2880   |   0.526664   |     -      |     -     |   14.08  \n",
            "   2    |  2900   |   0.576855   |     -      |     -     |   14.08  \n",
            "   2    |  2920   |   0.643186   |     -      |     -     |   14.09  \n",
            "   2    |  2940   |   0.580138   |     -      |     -     |   14.08  \n",
            "   2    |  2960   |   0.604996   |     -      |     -     |   14.09  \n",
            "   2    |  2980   |   0.551364   |     -      |     -     |   14.12  \n",
            "   2    |  3000   |   0.564080   |     -      |     -     |   14.09  \n",
            "   2    |  3020   |   0.564683   |     -      |     -     |   14.09  \n",
            "   2    |  3040   |   0.593425   |     -      |     -     |   14.07  \n",
            "   2    |  3060   |   0.508855   |     -      |     -     |   14.09  \n",
            "   2    |  3080   |   0.613786   |     -      |     -     |   14.09  \n",
            "   2    |  3100   |   0.543498   |     -      |     -     |   14.07  \n",
            "   2    |  3120   |   0.631185   |     -      |     -     |   14.08  \n",
            "   2    |  3140   |   0.539757   |     -      |     -     |   14.09  \n",
            "   2    |  3160   |   0.572261   |     -      |     -     |   14.11  \n",
            "   2    |  3180   |   0.508928   |     -      |     -     |   14.08  \n",
            "   2    |  3200   |   0.596579   |     -      |     -     |   14.09  \n",
            "   2    |  3220   |   0.578502   |     -      |     -     |   14.07  \n",
            "   2    |  3240   |   0.526068   |     -      |     -     |   14.07  \n",
            "   2    |  3260   |   0.541531   |     -      |     -     |   14.08  \n",
            "   2    |  3280   |   0.572888   |     -      |     -     |   14.09  \n",
            "   2    |  3300   |   0.529480   |     -      |     -     |   14.08  \n",
            "   2    |  3320   |   0.557505   |     -      |     -     |   14.09  \n",
            "   2    |  3340   |   0.582196   |     -      |     -     |   14.08  \n",
            "   2    |  3360   |   0.576291   |     -      |     -     |   14.08  \n",
            "   2    |  3380   |   0.573724   |     -      |     -     |   14.11  \n",
            "   2    |  3400   |   0.564877   |     -      |     -     |   14.09  \n",
            "   2    |  3420   |   0.541308   |     -      |     -     |   14.08  \n",
            "   2    |  3440   |   0.581597   |     -      |     -     |   14.07  \n",
            "   2    |  3460   |   0.588601   |     -      |     -     |   14.08  \n",
            "   2    |  3480   |   0.555477   |     -      |     -     |   14.11  \n",
            "   2    |  3500   |   0.604228   |     -      |     -     |   14.09  \n",
            "   2    |  3520   |   0.581485   |     -      |     -     |   14.09  \n",
            "   2    |  3540   |   0.556305   |     -      |     -     |   14.08  \n",
            "   2    |  3560   |   0.546047   |     -      |     -     |   14.10  \n",
            "   2    |  3580   |   0.583485   |     -      |     -     |   14.08  \n",
            "   2    |  3600   |   0.577167   |     -      |     -     |   14.08  \n",
            "   2    |  3620   |   0.542176   |     -      |     -     |   14.10  \n",
            "   2    |  3640   |   0.560338   |     -      |     -     |   14.09  \n",
            "   2    |  3660   |   0.561294   |     -      |     -     |   14.08  \n",
            "   2    |  3680   |   0.552846   |     -      |     -     |   14.10  \n",
            "   2    |  3700   |   0.534085   |     -      |     -     |   14.10  \n",
            "   2    |  3720   |   0.524195   |     -      |     -     |   14.08  \n",
            "   2    |  3740   |   0.575671   |     -      |     -     |   14.07  \n",
            "   2    |  3760   |   0.605302   |     -      |     -     |   14.08  \n",
            "   2    |  3780   |   0.616115   |     -      |     -     |   14.08  \n",
            "   2    |  3800   |   0.549578   |     -      |     -     |   14.08  \n",
            "   2    |  3820   |   0.601120   |     -      |     -     |   14.08  \n",
            "   2    |  3840   |   0.564193   |     -      |     -     |   14.09  \n",
            "   2    |  3860   |   0.490703   |     -      |     -     |   14.11  \n",
            "   2    |  3880   |   0.511674   |     -      |     -     |   14.07  \n",
            "   2    |  3900   |   0.588866   |     -      |     -     |   14.07  \n",
            "   2    |  3920   |   0.609047   |     -      |     -     |   14.08  \n",
            "   2    |  3940   |   0.550934   |     -      |     -     |   14.10  \n",
            "   2    |  3960   |   0.608459   |     -      |     -     |   14.09  \n",
            "   2    |  3980   |   0.519172   |     -      |     -     |   14.08  \n",
            "   2    |  4000   |   0.575132   |     -      |     -     |   14.11  \n",
            "   2    |  4020   |   0.550993   |     -      |     -     |   14.08  \n",
            "   2    |  4040   |   0.572442   |     -      |     -     |   14.08  \n",
            "   2    |  4060   |   0.526656   |     -      |     -     |   14.08  \n",
            "   2    |  4080   |   0.556961   |     -      |     -     |   14.08  \n",
            "   2    |  4100   |   0.567497   |     -      |     -     |   14.08  \n",
            "   2    |  4120   |   0.530555   |     -      |     -     |   14.10  \n",
            "   2    |  4140   |   0.554781   |     -      |     -     |   14.09  \n",
            "   2    |  4160   |   0.501310   |     -      |     -     |   14.08  \n",
            "   2    |  4180   |   0.492560   |     -      |     -     |   14.09  \n",
            "   2    |  4200   |   0.540323   |     -      |     -     |   14.09  \n",
            "   2    |  4220   |   0.531539   |     -      |     -     |   14.08  \n",
            "   2    |  4240   |   0.581876   |     -      |     -     |   14.10  \n",
            "   2    |  4260   |   0.556440   |     -      |     -     |   14.10  \n",
            "   2    |  4280   |   0.582231   |     -      |     -     |   14.09  \n",
            "   2    |  4300   |   0.551816   |     -      |     -     |   14.08  \n",
            "   2    |  4320   |   0.562023   |     -      |     -     |   14.08  \n",
            "   2    |  4340   |   0.566822   |     -      |     -     |   14.09  \n",
            "   2    |  4360   |   0.594346   |     -      |     -     |   14.07  \n",
            "   2    |  4380   |   0.528069   |     -      |     -     |   14.08  \n",
            "   2    |  4400   |   0.529512   |     -      |     -     |   14.09  \n",
            "   2    |  4420   |   0.557324   |     -      |     -     |   14.08  \n",
            "   2    |  4440   |   0.580801   |     -      |     -     |   14.08  \n",
            "   2    |  4460   |   0.528210   |     -      |     -     |   14.09  \n",
            "   2    |  4480   |   0.560217   |     -      |     -     |   14.10  \n",
            "   2    |  4500   |   0.568412   |     -      |     -     |   14.08  \n",
            "   2    |  4520   |   0.579410   |     -      |     -     |   14.09  \n",
            "   2    |  4540   |   0.538788   |     -      |     -     |   14.09  \n",
            "   2    |  4560   |   0.630999   |     -      |     -     |   14.08  \n",
            "   2    |  4580   |   0.551773   |     -      |     -     |   14.10  \n",
            "   2    |  4600   |   0.538781   |     -      |     -     |   14.09  \n",
            "   2    |  4620   |   0.540574   |     -      |     -     |   14.10  \n",
            "   2    |  4640   |   0.519642   |     -      |     -     |   14.08  \n",
            "   2    |  4660   |   0.581766   |     -      |     -     |   14.08  \n",
            "   2    |  4680   |   0.562239   |     -      |     -     |   14.09  \n",
            "   2    |  4700   |   0.545278   |     -      |     -     |   14.07  \n",
            "   2    |  4720   |   0.576095   |     -      |     -     |   14.09  \n",
            "   2    |  4740   |   0.560084   |     -      |     -     |   14.09  \n",
            "   2    |  4760   |   0.611918   |     -      |     -     |   14.08  \n",
            "   2    |  4780   |   0.486882   |     -      |     -     |   14.08  \n",
            "   2    |  4800   |   0.538499   |     -      |     -     |   14.07  \n",
            "   2    |  4820   |   0.580109   |     -      |     -     |   14.07  \n",
            "   2    |  4840   |   0.548302   |     -      |     -     |   14.09  \n",
            "   2    |  4860   |   0.597198   |     -      |     -     |   14.08  \n",
            "   2    |  4880   |   0.582395   |     -      |     -     |   14.08  \n",
            "   2    |  4900   |   0.523130   |     -      |     -     |   14.12  \n",
            "   2    |  4920   |   0.533647   |     -      |     -     |   14.12  \n",
            "   2    |  4940   |   0.553165   |     -      |     -     |   14.07  \n",
            "   2    |  4960   |   0.510001   |     -      |     -     |   14.10  \n",
            "   2    |  4980   |   0.560080   |     -      |     -     |   14.08  \n",
            "   2    |  5000   |   0.570291   |     -      |     -     |   14.09  \n",
            "   2    |  5020   |   0.542707   |     -      |     -     |   14.09  \n",
            "   2    |  5040   |   0.552605   |     -      |     -     |   14.08  \n",
            "   2    |  5052   |   0.491260   |     -      |     -     |   8.34   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.572558   |  0.650364  |   73.31   |  3684.68 \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.467910   |     -      |     -     |   14.81  \n",
            "   3    |   40    |   0.439523   |     -      |     -     |   14.09  \n",
            "   3    |   60    |   0.415979   |     -      |     -     |   14.11  \n",
            "   3    |   80    |   0.420495   |     -      |     -     |   14.08  \n",
            "   3    |   100   |   0.398547   |     -      |     -     |   14.08  \n",
            "   3    |   120   |   0.474808   |     -      |     -     |   14.08  \n",
            "   3    |   140   |   0.439650   |     -      |     -     |   14.08  \n",
            "   3    |   160   |   0.440804   |     -      |     -     |   14.08  \n",
            "   3    |   180   |   0.426244   |     -      |     -     |   14.07  \n",
            "   3    |   200   |   0.463597   |     -      |     -     |   14.07  \n",
            "   3    |   220   |   0.433208   |     -      |     -     |   14.08  \n",
            "   3    |   240   |   0.427049   |     -      |     -     |   14.08  \n",
            "   3    |   260   |   0.443895   |     -      |     -     |   14.11  \n",
            "   3    |   280   |   0.413213   |     -      |     -     |   14.09  \n",
            "   3    |   300   |   0.447596   |     -      |     -     |   14.07  \n",
            "   3    |   320   |   0.458795   |     -      |     -     |   14.09  \n",
            "   3    |   340   |   0.362815   |     -      |     -     |   14.08  \n",
            "   3    |   360   |   0.391962   |     -      |     -     |   14.08  \n",
            "   3    |   380   |   0.421649   |     -      |     -     |   14.07  \n",
            "   3    |   400   |   0.420286   |     -      |     -     |   14.10  \n",
            "   3    |   420   |   0.460941   |     -      |     -     |   14.09  \n",
            "   3    |   440   |   0.445875   |     -      |     -     |   14.08  \n",
            "   3    |   460   |   0.403737   |     -      |     -     |   14.09  \n",
            "   3    |   480   |   0.396314   |     -      |     -     |   14.08  \n",
            "   3    |   500   |   0.391460   |     -      |     -     |   14.09  \n",
            "   3    |   520   |   0.451642   |     -      |     -     |   14.08  \n",
            "   3    |   540   |   0.438917   |     -      |     -     |   14.09  \n",
            "   3    |   560   |   0.384981   |     -      |     -     |   14.08  \n",
            "   3    |   580   |   0.393763   |     -      |     -     |   14.08  \n",
            "   3    |   600   |   0.443698   |     -      |     -     |   14.09  \n",
            "   3    |   620   |   0.407745   |     -      |     -     |   14.08  \n",
            "   3    |   640   |   0.422555   |     -      |     -     |   14.09  \n",
            "   3    |   660   |   0.452089   |     -      |     -     |   14.08  \n",
            "   3    |   680   |   0.399274   |     -      |     -     |   14.09  \n",
            "   3    |   700   |   0.447286   |     -      |     -     |   14.08  \n",
            "   3    |   720   |   0.425589   |     -      |     -     |   14.08  \n",
            "   3    |   740   |   0.425624   |     -      |     -     |   14.08  \n",
            "   3    |   760   |   0.426430   |     -      |     -     |   14.08  \n",
            "   3    |   780   |   0.388850   |     -      |     -     |   14.09  \n",
            "   3    |   800   |   0.427304   |     -      |     -     |   14.10  \n",
            "   3    |   820   |   0.363450   |     -      |     -     |   14.09  \n",
            "   3    |   840   |   0.409157   |     -      |     -     |   14.09  \n",
            "   3    |   860   |   0.400362   |     -      |     -     |   14.08  \n",
            "   3    |   880   |   0.391722   |     -      |     -     |   14.08  \n",
            "   3    |   900   |   0.399451   |     -      |     -     |   14.07  \n",
            "   3    |   920   |   0.412621   |     -      |     -     |   14.09  \n",
            "   3    |   940   |   0.413034   |     -      |     -     |   14.08  \n",
            "   3    |   960   |   0.417159   |     -      |     -     |   14.08  \n",
            "   3    |   980   |   0.485238   |     -      |     -     |   14.10  \n",
            "   3    |  1000   |   0.362032   |     -      |     -     |   14.08  \n",
            "   3    |  1020   |   0.373394   |     -      |     -     |   14.08  \n",
            "   3    |  1040   |   0.403919   |     -      |     -     |   14.10  \n",
            "   3    |  1060   |   0.440579   |     -      |     -     |   14.07  \n",
            "   3    |  1080   |   0.416679   |     -      |     -     |   14.10  \n",
            "   3    |  1100   |   0.418852   |     -      |     -     |   14.10  \n",
            "   3    |  1120   |   0.370219   |     -      |     -     |   14.09  \n",
            "   3    |  1140   |   0.417391   |     -      |     -     |   14.10  \n",
            "   3    |  1160   |   0.386105   |     -      |     -     |   14.09  \n",
            "   3    |  1180   |   0.391586   |     -      |     -     |   14.09  \n",
            "   3    |  1200   |   0.378043   |     -      |     -     |   14.08  \n",
            "   3    |  1220   |   0.417679   |     -      |     -     |   14.09  \n",
            "   3    |  1240   |   0.435411   |     -      |     -     |   14.08  \n",
            "   3    |  1260   |   0.462769   |     -      |     -     |   14.09  \n",
            "   3    |  1280   |   0.417505   |     -      |     -     |   14.08  \n",
            "   3    |  1300   |   0.384241   |     -      |     -     |   14.10  \n",
            "   3    |  1320   |   0.371482   |     -      |     -     |   14.09  \n",
            "   3    |  1340   |   0.419348   |     -      |     -     |   14.09  \n",
            "   3    |  1360   |   0.398246   |     -      |     -     |   14.08  \n",
            "   3    |  1380   |   0.408643   |     -      |     -     |   14.08  \n",
            "   3    |  1400   |   0.418895   |     -      |     -     |   14.08  \n",
            "   3    |  1420   |   0.446763   |     -      |     -     |   14.07  \n",
            "   3    |  1440   |   0.461846   |     -      |     -     |   14.07  \n",
            "   3    |  1460   |   0.404769   |     -      |     -     |   14.07  \n",
            "   3    |  1480   |   0.434905   |     -      |     -     |   14.08  \n",
            "   3    |  1500   |   0.370190   |     -      |     -     |   14.09  \n",
            "   3    |  1520   |   0.409351   |     -      |     -     |   14.07  \n",
            "   3    |  1540   |   0.376032   |     -      |     -     |   14.09  \n",
            "   3    |  1560   |   0.397126   |     -      |     -     |   14.08  \n",
            "   3    |  1580   |   0.357358   |     -      |     -     |   14.08  \n",
            "   3    |  1600   |   0.429882   |     -      |     -     |   14.08  \n",
            "   3    |  1620   |   0.393791   |     -      |     -     |   14.08  \n",
            "   3    |  1640   |   0.340746   |     -      |     -     |   14.09  \n",
            "   3    |  1660   |   0.397619   |     -      |     -     |   14.08  \n",
            "   3    |  1680   |   0.450334   |     -      |     -     |   14.08  \n",
            "   3    |  1700   |   0.412297   |     -      |     -     |   14.10  \n",
            "   3    |  1720   |   0.408264   |     -      |     -     |   14.09  \n",
            "   3    |  1740   |   0.441255   |     -      |     -     |   14.10  \n",
            "   3    |  1760   |   0.463781   |     -      |     -     |   14.08  \n",
            "   3    |  1780   |   0.442600   |     -      |     -     |   14.07  \n",
            "   3    |  1800   |   0.419201   |     -      |     -     |   14.07  \n",
            "   3    |  1820   |   0.446386   |     -      |     -     |   14.09  \n",
            "   3    |  1840   |   0.388221   |     -      |     -     |   14.08  \n",
            "   3    |  1860   |   0.409847   |     -      |     -     |   14.09  \n",
            "   3    |  1880   |   0.419183   |     -      |     -     |   14.08  \n",
            "   3    |  1900   |   0.413141   |     -      |     -     |   14.08  \n",
            "   3    |  1920   |   0.477563   |     -      |     -     |   14.08  \n",
            "   3    |  1940   |   0.398189   |     -      |     -     |   14.08  \n",
            "   3    |  1960   |   0.411819   |     -      |     -     |   14.10  \n",
            "   3    |  1980   |   0.465802   |     -      |     -     |   14.09  \n",
            "   3    |  2000   |   0.452848   |     -      |     -     |   14.08  \n",
            "   3    |  2020   |   0.346732   |     -      |     -     |   14.08  \n",
            "   3    |  2040   |   0.383535   |     -      |     -     |   14.10  \n",
            "   3    |  2060   |   0.434354   |     -      |     -     |   14.09  \n",
            "   3    |  2080   |   0.401762   |     -      |     -     |   14.08  \n",
            "   3    |  2100   |   0.398227   |     -      |     -     |   14.07  \n",
            "   3    |  2120   |   0.389661   |     -      |     -     |   14.09  \n",
            "   3    |  2140   |   0.427500   |     -      |     -     |   14.07  \n",
            "   3    |  2160   |   0.370453   |     -      |     -     |   14.08  \n",
            "   3    |  2180   |   0.462711   |     -      |     -     |   14.08  \n",
            "   3    |  2200   |   0.402733   |     -      |     -     |   14.09  \n",
            "   3    |  2220   |   0.387051   |     -      |     -     |   14.09  \n",
            "   3    |  2240   |   0.471540   |     -      |     -     |   14.08  \n",
            "   3    |  2260   |   0.459483   |     -      |     -     |   14.07  \n",
            "   3    |  2280   |   0.405637   |     -      |     -     |   14.10  \n",
            "   3    |  2300   |   0.403898   |     -      |     -     |   14.07  \n",
            "   3    |  2320   |   0.369127   |     -      |     -     |   14.08  \n",
            "   3    |  2340   |   0.430633   |     -      |     -     |   14.08  \n",
            "   3    |  2360   |   0.488094   |     -      |     -     |   14.07  \n",
            "   3    |  2380   |   0.349171   |     -      |     -     |   14.07  \n",
            "   3    |  2400   |   0.444404   |     -      |     -     |   14.08  \n",
            "   3    |  2420   |   0.429995   |     -      |     -     |   14.08  \n",
            "   3    |  2440   |   0.396558   |     -      |     -     |   14.09  \n",
            "   3    |  2460   |   0.353214   |     -      |     -     |   14.09  \n",
            "   3    |  2480   |   0.403304   |     -      |     -     |   14.08  \n",
            "   3    |  2500   |   0.417453   |     -      |     -     |   14.08  \n",
            "   3    |  2520   |   0.424140   |     -      |     -     |   14.08  \n",
            "   3    |  2540   |   0.479683   |     -      |     -     |   14.08  \n",
            "   3    |  2560   |   0.440485   |     -      |     -     |   14.09  \n",
            "   3    |  2580   |   0.411741   |     -      |     -     |   14.09  \n",
            "   3    |  2600   |   0.406524   |     -      |     -     |   14.08  \n",
            "   3    |  2620   |   0.450857   |     -      |     -     |   14.08  \n",
            "   3    |  2640   |   0.400055   |     -      |     -     |   14.09  \n",
            "   3    |  2660   |   0.380937   |     -      |     -     |   14.08  \n",
            "   3    |  2680   |   0.371242   |     -      |     -     |   14.08  \n",
            "   3    |  2700   |   0.438969   |     -      |     -     |   14.07  \n",
            "   3    |  2720   |   0.426987   |     -      |     -     |   14.08  \n",
            "   3    |  2740   |   0.445429   |     -      |     -     |   14.08  \n",
            "   3    |  2760   |   0.418777   |     -      |     -     |   14.07  \n",
            "   3    |  2780   |   0.389179   |     -      |     -     |   14.07  \n",
            "   3    |  2800   |   0.417122   |     -      |     -     |   14.09  \n",
            "   3    |  2820   |   0.419150   |     -      |     -     |   14.08  \n",
            "   3    |  2840   |   0.391556   |     -      |     -     |   14.10  \n",
            "   3    |  2860   |   0.382078   |     -      |     -     |   14.10  \n",
            "   3    |  2880   |   0.387981   |     -      |     -     |   14.07  \n",
            "   3    |  2900   |   0.460625   |     -      |     -     |   14.08  \n",
            "   3    |  2920   |   0.439017   |     -      |     -     |   14.08  \n",
            "   3    |  2940   |   0.376109   |     -      |     -     |   14.09  \n",
            "   3    |  2960   |   0.422495   |     -      |     -     |   14.08  \n",
            "   3    |  2980   |   0.352351   |     -      |     -     |   14.08  \n",
            "   3    |  3000   |   0.375698   |     -      |     -     |   14.08  \n",
            "   3    |  3020   |   0.376845   |     -      |     -     |   14.08  \n",
            "   3    |  3040   |   0.390349   |     -      |     -     |   14.12  \n",
            "   3    |  3060   |   0.416296   |     -      |     -     |   14.08  \n",
            "   3    |  3080   |   0.480251   |     -      |     -     |   14.08  \n",
            "   3    |  3100   |   0.351693   |     -      |     -     |   14.08  \n",
            "   3    |  3120   |   0.352771   |     -      |     -     |   14.09  \n",
            "   3    |  3140   |   0.362287   |     -      |     -     |   14.10  \n",
            "   3    |  3160   |   0.368676   |     -      |     -     |   14.10  \n",
            "   3    |  3180   |   0.412963   |     -      |     -     |   14.09  \n",
            "   3    |  3200   |   0.411221   |     -      |     -     |   14.10  \n",
            "   3    |  3220   |   0.362435   |     -      |     -     |   14.10  \n",
            "   3    |  3240   |   0.399115   |     -      |     -     |   14.10  \n",
            "   3    |  3260   |   0.413173   |     -      |     -     |   14.09  \n",
            "   3    |  3280   |   0.396812   |     -      |     -     |   14.08  \n",
            "   3    |  3300   |   0.337627   |     -      |     -     |   14.11  \n",
            "   3    |  3320   |   0.406154   |     -      |     -     |   14.10  \n",
            "   3    |  3340   |   0.380076   |     -      |     -     |   14.08  \n",
            "   3    |  3360   |   0.350286   |     -      |     -     |   14.08  \n",
            "   3    |  3380   |   0.366379   |     -      |     -     |   14.10  \n",
            "   3    |  3400   |   0.398040   |     -      |     -     |   14.09  \n",
            "   3    |  3420   |   0.422299   |     -      |     -     |   14.09  \n",
            "   3    |  3440   |   0.411388   |     -      |     -     |   14.10  \n",
            "   3    |  3460   |   0.436983   |     -      |     -     |   14.08  \n",
            "   3    |  3480   |   0.381909   |     -      |     -     |   14.07  \n",
            "   3    |  3500   |   0.377068   |     -      |     -     |   14.07  \n",
            "   3    |  3520   |   0.345301   |     -      |     -     |   14.09  \n",
            "   3    |  3540   |   0.402886   |     -      |     -     |   14.09  \n",
            "   3    |  3560   |   0.393094   |     -      |     -     |   14.10  \n",
            "   3    |  3580   |   0.431834   |     -      |     -     |   14.09  \n",
            "   3    |  3600   |   0.387134   |     -      |     -     |   14.11  \n",
            "   3    |  3620   |   0.403361   |     -      |     -     |   14.08  \n",
            "   3    |  3640   |   0.426996   |     -      |     -     |   14.11  \n",
            "   3    |  3660   |   0.425109   |     -      |     -     |   14.11  \n",
            "   3    |  3680   |   0.374474   |     -      |     -     |   14.09  \n",
            "   3    |  3700   |   0.440771   |     -      |     -     |   14.09  \n",
            "   3    |  3720   |   0.367204   |     -      |     -     |   14.10  \n",
            "   3    |  3740   |   0.386775   |     -      |     -     |   14.14  \n",
            "   3    |  3760   |   0.366084   |     -      |     -     |   14.11  \n",
            "   3    |  3780   |   0.419804   |     -      |     -     |   14.11  \n",
            "   3    |  3800   |   0.377832   |     -      |     -     |   14.08  \n",
            "   3    |  3820   |   0.403714   |     -      |     -     |   14.08  \n",
            "   3    |  3840   |   0.397310   |     -      |     -     |   14.09  \n",
            "   3    |  3860   |   0.437724   |     -      |     -     |   14.09  \n",
            "   3    |  3880   |   0.354831   |     -      |     -     |   14.07  \n",
            "   3    |  3900   |   0.431833   |     -      |     -     |   14.08  \n",
            "   3    |  3920   |   0.375390   |     -      |     -     |   14.09  \n",
            "   3    |  3940   |   0.374725   |     -      |     -     |   14.07  \n",
            "   3    |  3960   |   0.447183   |     -      |     -     |   14.08  \n",
            "   3    |  3980   |   0.411825   |     -      |     -     |   14.10  \n",
            "   3    |  4000   |   0.353128   |     -      |     -     |   14.12  \n",
            "   3    |  4020   |   0.400068   |     -      |     -     |   14.09  \n",
            "   3    |  4040   |   0.379854   |     -      |     -     |   14.11  \n",
            "   3    |  4060   |   0.421183   |     -      |     -     |   14.07  \n",
            "   3    |  4080   |   0.360656   |     -      |     -     |   14.12  \n",
            "   3    |  4100   |   0.377457   |     -      |     -     |   14.10  \n",
            "   3    |  4120   |   0.379315   |     -      |     -     |   14.10  \n",
            "   3    |  4140   |   0.385735   |     -      |     -     |   14.07  \n",
            "   3    |  4160   |   0.380597   |     -      |     -     |   14.10  \n",
            "   3    |  4180   |   0.359643   |     -      |     -     |   14.08  \n",
            "   3    |  4200   |   0.348725   |     -      |     -     |   14.08  \n",
            "   3    |  4220   |   0.356454   |     -      |     -     |   14.08  \n",
            "   3    |  4240   |   0.407176   |     -      |     -     |   14.09  \n",
            "   3    |  4260   |   0.392618   |     -      |     -     |   14.09  \n",
            "   3    |  4280   |   0.408185   |     -      |     -     |   14.09  \n",
            "   3    |  4300   |   0.391793   |     -      |     -     |   14.08  \n",
            "   3    |  4320   |   0.390709   |     -      |     -     |   14.08  \n",
            "   3    |  4340   |   0.406505   |     -      |     -     |   14.08  \n",
            "   3    |  4360   |   0.391495   |     -      |     -     |   14.08  \n",
            "   3    |  4380   |   0.429939   |     -      |     -     |   14.08  \n",
            "   3    |  4400   |   0.370578   |     -      |     -     |   14.09  \n",
            "   3    |  4420   |   0.384899   |     -      |     -     |   14.07  \n",
            "   3    |  4440   |   0.391873   |     -      |     -     |   14.07  \n",
            "   3    |  4460   |   0.365855   |     -      |     -     |   14.09  \n",
            "   3    |  4480   |   0.355655   |     -      |     -     |   14.08  \n",
            "   3    |  4500   |   0.417517   |     -      |     -     |   14.08  \n",
            "   3    |  4520   |   0.423827   |     -      |     -     |   14.09  \n",
            "   3    |  4540   |   0.422129   |     -      |     -     |   14.07  \n",
            "   3    |  4560   |   0.430280   |     -      |     -     |   14.07  \n",
            "   3    |  4580   |   0.435768   |     -      |     -     |   14.07  \n",
            "   3    |  4600   |   0.359251   |     -      |     -     |   14.09  \n",
            "   3    |  4620   |   0.373118   |     -      |     -     |   14.08  \n",
            "   3    |  4640   |   0.394414   |     -      |     -     |   14.12  \n",
            "   3    |  4660   |   0.384442   |     -      |     -     |   14.09  \n",
            "   3    |  4680   |   0.405665   |     -      |     -     |   14.08  \n",
            "   3    |  4700   |   0.396525   |     -      |     -     |   14.08  \n",
            "   3    |  4720   |   0.394466   |     -      |     -     |   14.08  \n",
            "   3    |  4740   |   0.389378   |     -      |     -     |   14.09  \n",
            "   3    |  4760   |   0.395717   |     -      |     -     |   14.08  \n",
            "   3    |  4780   |   0.410292   |     -      |     -     |   14.08  \n",
            "   3    |  4800   |   0.383699   |     -      |     -     |   14.09  \n",
            "   3    |  4820   |   0.374145   |     -      |     -     |   14.10  \n",
            "   3    |  4840   |   0.361888   |     -      |     -     |   14.08  \n",
            "   3    |  4860   |   0.363509   |     -      |     -     |   14.07  \n",
            "   3    |  4880   |   0.396718   |     -      |     -     |   14.08  \n",
            "   3    |  4900   |   0.434708   |     -      |     -     |   14.07  \n",
            "   3    |  4920   |   0.361178   |     -      |     -     |   14.08  \n",
            "   3    |  4940   |   0.398157   |     -      |     -     |   14.08  \n",
            "   3    |  4960   |   0.409912   |     -      |     -     |   14.09  \n",
            "   3    |  4980   |   0.394906   |     -      |     -     |   14.07  \n",
            "   3    |  5000   |   0.416076   |     -      |     -     |   14.09  \n",
            "   3    |  5020   |   0.419926   |     -      |     -     |   14.07  \n",
            "   3    |  5040   |   0.382875   |     -      |     -     |   14.07  \n",
            "   3    |  5052   |   0.396222   |     -      |     -     |   8.33   \n",
            "----------------------------------------------------------------------\n",
            "   3    |    -    |   0.406225   |  0.686783  |   74.49   |  3684.69 \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# initialize model and begin training!\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=3, train_dataloader=train_dataloader)\n",
        "train(bert_classifier, train_dataloader, test_dataloader, epochs=3, evaluation=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp bert_eng_full_review_2.pt /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "MShNIifWZSi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_X = pd.read_csv('/content/drive/MyDrive/CWT Data/X_test.csv')\n",
        "test_y = pd.read_csv('/content/drive/MyDrive/CWT Data/y_test.csv')"
      ],
      "metadata": {
        "id": "qmkX_oDrqqSC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    test_accuracy = []\n",
        "    test_loss = []\n",
        "    test_roc = []\n",
        "    test_f1 = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for step, batch in enumerate(val_dataloader):\n",
        "\n",
        "        from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "        # Load batch to GPU\n",
        "\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to('cpu') for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        test_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        probabilities = nn.functional.softmax(logits, dim=-1).detach().numpy()\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        test_accuracy.append(accuracy)\n",
        "\n",
        "        roc = roc_auc_score(b_labels, probabilities, average='macro', multi_class='ovr')\n",
        "        test_roc.append(roc)\n",
        "\n",
        "        f1_score = f1_score(b_labels, preds.detach().numpy(), average='macro')\n",
        "        test_f1.append(f1_score)\n",
        "\n",
        "        if (step % 20 == 0):\n",
        "          print(step, np.mean(test_roc))\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    test_loss = np.mean(test_loss)\n",
        "    test_accuracy = np.mean(val_accuracy)\n",
        "    test_roc = np.mean(test_roc)\n",
        "    test_f1 = np.mean(test_f1)\n",
        "\n",
        "    return test_loss, test_accuracy, test_roc, test_f1"
      ],
      "metadata": {
        "id": "yUzQgtTIq8J0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "  model = BertClassifier(freeze_bert=True)\n",
        "  model.load_state_dict(torch.load('/content/drive/MyDrive/bert_eng_full_review_2.pt', map_location=torch.device('cuda'))['model_state_dict'])\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "  return tokenizer, model"
      ],
      "metadata": {
        "id": "0EeUrPxxz4lP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer, model = load_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eGKhM4_0A_p",
        "outputId": "cebb404f-8186-45d8-b2f1-baf9ecd8e628"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs, test_masks = preprocessing_for_bert(test_X.review_full.values)\n",
        "test_labels = torch.tensor(test_y.rating_review.values)\n",
        "test_labels = test_labels.type(torch.LongTensor)\n",
        "test_labels = test_labels - 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuwS7cHK0DDC",
        "outputId": "64d1b39e-6003-4aa1-f3be-5b6887095d57"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 8085/8085 [00:20<00:00, 388.82it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the DataLoader for our validation set\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "ah6Jud790jIS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, val_accuracy, test_roc, test_f1 = evaluate(model, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "tXQNAJM82GmW",
        "outputId": "8aa66e37-ab41-475f-e73c-dfa785f8b1c6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.9202858807858808\n",
            "20 0.957084314007995\n",
            "40 0.9588121788485127\n",
            "60 0.9557686449505121\n",
            "80 0.9550429060169028\n",
            "100 0.9558766573488405\n",
            "120 0.9569609338953969\n",
            "140 0.9573204085170887\n",
            "160 0.9577880719324405\n",
            "180 0.9580751227981668\n",
            "200 0.9573806948355792\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-ede1b4fd004e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_roc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-409dc692fe9e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, val_dataloader)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mtest_roc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         return _multiclass_roc_auc_score(\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         )\n\u001b[1;32m    564\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             raise ValueError(\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0;34m\"Number of classes in y_true not equal to the number of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m                 \u001b[0;34m\"columns in 'y_score'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Number of classes in y_true not equal to the number of columns in 'y_score'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "euenyRhjFVFu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e47da83e3904d6384710e7563d6ff60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72f6f4f313a2436c8fe887fcfd86095e",
              "IPY_MODEL_e6b74e1e2173451f93658099fae7e87b",
              "IPY_MODEL_f9f6900239d14043b17699119a019542"
            ],
            "layout": "IPY_MODEL_24a25b9cca0a43aa801cbee96dab6eba"
          }
        },
        "72f6f4f313a2436c8fe887fcfd86095e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a50cd813e3854aa68ee429fde7afb2b3",
            "placeholder": "",
            "style": "IPY_MODEL_04186e99b4594f57a4bff86682915c68",
            "value": "Downloading: 100%"
          }
        },
        "e6b74e1e2173451f93658099fae7e87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fa170d651cc4e5b816f238402bd9b2e",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c81261a2391d47e39e1d1a00d2a345c4",
            "value": 440473133
          }
        },
        "f9f6900239d14043b17699119a019542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b350421366d4fc59bcb91429aa342ca",
            "placeholder": "",
            "style": "IPY_MODEL_293fee50998f47c498ea51200f880f55",
            "value": " 440M/440M [00:08&lt;00:00, 56.1MB/s]"
          }
        },
        "24a25b9cca0a43aa801cbee96dab6eba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a50cd813e3854aa68ee429fde7afb2b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04186e99b4594f57a4bff86682915c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fa170d651cc4e5b816f238402bd9b2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c81261a2391d47e39e1d1a00d2a345c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b350421366d4fc59bcb91429aa342ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293fee50998f47c498ea51200f880f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc0260560a9742d6979c5481ef0974b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ea0be78bc0a4ce9a2300aff9904626c",
              "IPY_MODEL_0c6ee89579184448b153ed5c3a04ff6c",
              "IPY_MODEL_3a429b3258e44d738414e9615f062761"
            ],
            "layout": "IPY_MODEL_288d2528c68346bb993da63b690ea394"
          }
        },
        "7ea0be78bc0a4ce9a2300aff9904626c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8db5374107834c2ead2bb4e0f29dfcfd",
            "placeholder": "",
            "style": "IPY_MODEL_20db29c280334d1c9a2f25d817e5e802",
            "value": "Downloading: 100%"
          }
        },
        "0c6ee89579184448b153ed5c3a04ff6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f303ffc51ee48a7a452728bafe3ffa2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33b9323fb04644d7855eddf32faf134a",
            "value": 231508
          }
        },
        "3a429b3258e44d738414e9615f062761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9829e0aa9184a0ea8709cc7aaa5bd31",
            "placeholder": "",
            "style": "IPY_MODEL_9bc0dc16fea84d8da6fe87a0469ef2a0",
            "value": " 232k/232k [00:00&lt;00:00, 250kB/s]"
          }
        },
        "288d2528c68346bb993da63b690ea394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8db5374107834c2ead2bb4e0f29dfcfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20db29c280334d1c9a2f25d817e5e802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f303ffc51ee48a7a452728bafe3ffa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33b9323fb04644d7855eddf32faf134a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9829e0aa9184a0ea8709cc7aaa5bd31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc0dc16fea84d8da6fe87a0469ef2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cd8a2bfe60f4a0786f322b107d51547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_630636c220a54fc3b001fce729c366bb",
              "IPY_MODEL_63b2d0583a724e46962fc8a552791d2a",
              "IPY_MODEL_ec07bef5055941e6a35d67f05fdae6d6"
            ],
            "layout": "IPY_MODEL_6932b3917c904cd5b95ea63f7eb66405"
          }
        },
        "630636c220a54fc3b001fce729c366bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22573f36ebb049e78deb49abea79ba29",
            "placeholder": "",
            "style": "IPY_MODEL_7de209d55ad34e9884117a4124d1fea0",
            "value": "Downloading: 100%"
          }
        },
        "63b2d0583a724e46962fc8a552791d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74ddf32e38534128b5cbcd3bc8078c21",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f75ad83c01c4ce58d8895985b3abb23",
            "value": 28
          }
        },
        "ec07bef5055941e6a35d67f05fdae6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c0906e6b8d3451c9d0b03dbc2c45d8d",
            "placeholder": "",
            "style": "IPY_MODEL_dd3534601a074519bcd264340dab7d43",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.07kB/s]"
          }
        },
        "6932b3917c904cd5b95ea63f7eb66405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22573f36ebb049e78deb49abea79ba29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de209d55ad34e9884117a4124d1fea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74ddf32e38534128b5cbcd3bc8078c21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f75ad83c01c4ce58d8895985b3abb23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c0906e6b8d3451c9d0b03dbc2c45d8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd3534601a074519bcd264340dab7d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fce4a93c1ce4f3ba03d0d943d710f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91a632b3a9424573a558baaa68e16ea2",
              "IPY_MODEL_5847586e0cc24ece9125b4cd7b2735bc",
              "IPY_MODEL_39eac88e4a114f63bab6658d03e87727"
            ],
            "layout": "IPY_MODEL_af79cb8b1edf42c68dada28f42318506"
          }
        },
        "91a632b3a9424573a558baaa68e16ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_590431fde48349b1abab0422aa8f9c72",
            "placeholder": "",
            "style": "IPY_MODEL_1c7b0c881c25489187be010f52fe7509",
            "value": "Downloading: 100%"
          }
        },
        "5847586e0cc24ece9125b4cd7b2735bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00a52ed536e54368bde99bc5f4ab9b8d",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15548afeef224f16a9c92705c5e27237",
            "value": 570
          }
        },
        "39eac88e4a114f63bab6658d03e87727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b284b522d77943e9a11de1d8b2ac6eb7",
            "placeholder": "",
            "style": "IPY_MODEL_a115d567faf340f98f2939eb604f66f9",
            "value": " 570/570 [00:00&lt;00:00, 24.7kB/s]"
          }
        },
        "af79cb8b1edf42c68dada28f42318506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "590431fde48349b1abab0422aa8f9c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c7b0c881c25489187be010f52fe7509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00a52ed536e54368bde99bc5f4ab9b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15548afeef224f16a9c92705c5e27237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b284b522d77943e9a11de1d8b2ac6eb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a115d567faf340f98f2939eb604f66f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}